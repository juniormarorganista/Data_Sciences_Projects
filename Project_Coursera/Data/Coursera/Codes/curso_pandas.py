# -*- coding: utf-8 -*-
"""Curso Pandas.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1b6kmyArjxkBcUJlpxtuNpvpAwU3_g11A

# Instalação do Pandas
"""

!pip install pandas
#!pip install pandas==1.5.3

import pandas as pd
import numpy as np
print(pd.__version__)
print(np.__version__)

"""# Series

- Documentação: https://pandas.pydata.org/docs/reference/api/pandas.Series.html

## Criação de series
"""

serie_dados = pd.Series([10, 20, 30, 40, 50])
print(serie_dados)

type(serie_dados)

array_inteiros = [10, 20, 30, 40, 50]
indices = ['A', 'B', 'C', 'D', 'E']
serie_dados = pd.Series(array_inteiros, index=indices)
print(serie_dados)

np_array_inteiros = np.array([10,20,30,40,50])
print(np_array_inteiros)

type(np_array_inteiros)

serie_dados = pd.Series(array_inteiros)
print(serie_dados)

serie_dados.shape

serie_dados.ndim

serie_dados.size

serie_dados

serie_dados.index = ['Z', 'X', 'V', 'A', 'B']
serie_dados

valores = np.random.random(10)
indexes = np.arange(0,10)
print(valores)
print(indexes)

type(valores), type(indexes)

serie_dados = pd.Series(valores, indexes)
print(serie_dados)

serie_dados.index

dicionario = {'João': 10, 'Alice': 5, 'Gustavo': 6, 'Pedro': 9}
type(dicionario)

dicionario

dict_serie_dados = pd.Series(dicionario)
print(dict_serie_dados)

dict_serie_dados.dtype

"""## Fatiamento (slicing)"""

serie_dados[:]

serie_dados[0:3]

serie_dados[:4]

serie_dados[-1:]

serie_dados[:-1]

s2 = serie_dados[:3]
s2

"""## Cópia, conversão e concatenação"""

#serie_dados2 = serie_dados
serie_dados2 = serie_dados.copy()
serie_dados2

serie_dados2.dtype

serie_dados2 = serie_dados2.astype(int)

serie_dados2.dtype

dados_novos = {'Gustavo': 20, 'Alana': 30}
serie_dados3 = pd.Series(dados_novos)
serie_dados3

dict_serie_dados

serie_dados4 = pd.concat([dict_serie_dados, serie_dados3])
serie_dados4

"""## Acesso aos dados com iloc

- Acessar elementos pelo índice
"""

dataset = pd.read_csv('census.csv')

type(dataset)

dataset

serie_idade = dataset['age']
serie_idade

type(serie_idade)

dataset['age'].values, type(dataset['age'].values)

serie_idade.head()

serie_idade.head(10)

serie_idade.tail()

serie_idade.tail(10)

serie_idade.iloc[0]

serie_idade.iloc[32551]

serie_idade.iloc[-1]

serie_idade.iloc[0:3]

serie_idade.iloc[0:5]

serie_idade.iloc[[0,2,4]]

lista_idade = []
for i in serie_idade.items():
  #print(i)
  #print(i[0], i[1])
  if i[1] > 50:
    lista_idade.append(i[0])

print(lista_idade)

serie_idade.iloc[lista_idade]

"""## Acesso aos dados com loc

- Acessar elementos por "string"
"""

# https://faker.readthedocs.io/en/master/
!pip install Faker

from faker import Faker
fake = Faker()

fake.name()

indices_nome = []
for _ in range(32561):
  indices_nome.append(fake.name())

type(indices_nome), len(indices_nome)

indices_nome[0:10]

serie_idade.size

serie_idade_nome = pd.Series(np.array(dataset['age']), index = indices_nome)
serie_idade_nome

serie_idade_nome["Donald Torres"]

serie_idade_nome["Eric Palmer"]

serie_idade_nome["Kelly Russell"]

serie_idade_nome2 = serie_idade_nome.drop_duplicates()
serie_idade_nome2.size

serie_idade_nome2

serie_idade_nome2.loc["Donald Torres":"Kelly Russell"]

serie_idade_nome2.loc[["Donald Torres", "Lawrence Le"]]

serie_idade_nome2.index

serie_idade_nome3 = serie_idade_nome2.copy()
serie_idade_nome3

serie_idade_nome3.reset_index(drop = True, inplace = True)

serie_idade_nome3

serie_idade_nome3.index

"""## Ordenação"""

serie_idade_nome.sort_values()

serie_idade_nome.sort_values(ascending = False)

serie_idade_nome.sort_index(ascending = True)

serie_idade_nome.sort_index(ascending = False)

sr = serie_idade_nome.sort_values(ascending = False).iloc[0:11]
sr

"""## Contagem"""

serie_idade_nome.size

serie_idade_nome

serie_idade_nome.value_counts()

serie_idade_nome.value_counts(normalize = True, sort = True)

serie_idade_nome.value_counts(bins = 10)

"""## Filtros"""

fake.country()

indices_pais = []
for _ in range(32561):
  indices_pais.append(fake.country())

indices_pais[0:11]

serie_pais = pd.Series(np.array(dataset['age']), index = indices_pais)
serie_pais

serie_pais.loc[serie_pais > 50]

serie_pais.loc[(serie_pais > 50) & (serie_pais.index == "India")]

serie_pais.index.isin(["India", "Brazil"])

~serie_pais.index.isin(["India", "Brazil"])

"""## Operações matemáticas"""

serie_pais

serie_pais + 2

serie_pais.add(2)

serie_pais.sub(2)

serie_pais.mul(2)

serie_pais.div(2)

s1 = pd.Series([20,30,40])
s2 = pd.Series([1,2,3])
s1,s2

s1.add(s2)

s1.sub(s2)

s1.mul(s2)

s1.div(s2)

"""## Operações com strings"""

serie_pais

serie_pais_index = serie_pais.index.to_series()
serie_pais_index.reset_index(drop = True, inplace = True)
serie_pais_index

serie_pais_index.str.contains("tse")

serie_pais_index.str.upper()

serie_pais_index.str.lower()

serie_pais_index.str.strip("Libyan")

serie_pais_index.str.split(' ', expand = True)

serie_pais_index.str[0:5]

"""## Agrupamento numérico"""

serie_pais

serie_pais.sum()

serie_pais.mean()

serie_pais.median()

serie_pais.count()

serie_pais.std()

serie_pais.var()

serie_pais.loc["Brazil"].mean()

serie_pais.loc["India"].mean()

serie_pais.quantile([0.25, 0.5, 0.75])

"""## Agrupamento categórico"""

serie_pais_index

serie_pais_index.value_counts()

serie_pais_index.value_counts(normalize = True)

serie_pais_index.unique()

serie_pais_index.nunique()

"""## Valores faltantes"""

serie_faltante = pd.Series([1, 2, 3, np.nan, 5, np.nan])
serie_faltante

serie_faltante.isna()

serie_faltante.isna().sum()

serie_faltante.value_counts(dropna = False)

serie_faltante.fillna(0)

serie_faltante.dropna()

serie_faltante.fillna(serie_faltante.mean())

serie_faltante = pd.Series(["Maçã", "Banana", "Arroz", "Arroz", np.nan, "Batata"])
serie_faltante

serie_faltante.isna().sum()

serie_faltante.fillna("Não informado")

serie_faltante.mode().iloc[0]

serie_faltante.fillna(serie_faltante.mode().iloc[0])

"""## Funções"""

serie_idade

serie_idade.loc[serie_idade < 18]

def corrige_idade(idade):
  if idade < 18:
    idade = 18
  return idade

corrige_idade(20)

corrige_idade(17)

serie_idade = serie_idade.apply(corrige_idade)

serie_idade.loc[serie_idade < 18]

serie_idade = serie_idade.apply(lambda x: 17 if x == 18 else x)

serie_idade.loc[serie_idade < 18]

serie_idade2 = serie_idade.iloc[0:6]
serie_idade2

serie_idade2.where(serie_idade2 < 40, 0)

"""# Dataframe

## Criação de dataframes
"""

data = [['Alice', 25, 'São Paulo'],
        ['João', 30, 'Rio de Janeiro'],
        ['Bruno', 35, 'Curitiba'],
        ['Carlos', 40, 'Manaus']]

type(data)

colunas = ['Nome', 'Idade', 'Cidade']

df = pd.DataFrame(data, columns=colunas)
df

data = {'Nome': ['Alice', 'João', 'Bruno', 'Carlos'],
        'Idade': [25, 30, 35, 40],
        'Cidade': ['São Paulo', 'Rio de Janeiro', 'Curitiba', 'Manaus']}
data

type(data)

df = pd.DataFrame(data)
df

data = np.array([['Alice', 25, 'São Paulo'],
                 ['João', 30, 'Rio de Janeiro'],
                 ['Bruno', 35, 'Curitiba'],
                 ['Carlos', 40, 'Manaus']])
type(data)

data

df = pd.DataFrame(data, columns = colunas)
df

data = [('Alice', 25, 'São Paulo'),
        ('João', 30, 'Rio de Janeiro'),
        ('Bruno', 35, 'Curitiba'),
        ('Carlos', 40, 'Manaus')]

type(data), type(data[0])

data

df = pd.DataFrame(data, columns = colunas)
df

data = {'Nome': pd.Series(['Alice', 'João', 'Bruno', 'Carlos']),
        'Idade': pd.Series([25, 30, 35, 40]),
        'Cidade': pd.Series(['São Paulo', 'Rio de Janeiro', 'Curitiba', 'Manaus'])}
data

type(data)

df = pd.DataFrame(data)
df

data = {'Nome': np.array(['Alice', 'João', 'Bruno', 'Carlos']),
        'Idade': np.array([25, 30, 35, 40]),
        'Cidade': np.array(['São Paulo', 'Rio de Janeiro', 'Curitiba', 'Manaus'])}
data

type(data)

df = pd.DataFrame(data)
df

"""## Exploração de dataframes"""

dataset = pd.read_csv('census.csv')

dataset

dataset.head(6)

dataset.tail()

dataset.shape

32561 * 15

dataset.size

dataset.index

dataset.columns

dataset.axes

dataset.dtypes

dataset.info()

dataset.describe()

"""## Acesso com loc e iloc"""

dataset["age"]

type(dataset["age"])

dataset.age

dataset.age.mean()

dataset.age.iloc[0:4]

dataset[["age", "education"]]

dataset.iloc[0:4,0:4] # linha, coluna

dataset.iloc[0:4, :]

dataset.iloc[0:4,[0,3,5]]

dataset.iloc[:, 0:4]

dataset.loc[:, "age"]

dataset.loc[:, ["age", "workclass", "education"]]

dataset.loc[0:5, "age":"occupation"]

"""## Apagar linhas e colunas"""

dataset.drop("education", axis = 1) # 0 - linhas, 1 - colunas

dataset.drop("final-weight", axis = 1, inplace = True)

dataset.columns

dataset.drop([0], axis = 0)

dataset.drop([0], axis = 0, inplace = True)

dataset

dataset.reset_index(drop = True, inplace = True)

dataset.head()

"""## Linhas duplicadas"""

dataset.duplicated()

dataset.duplicated().sum()

dataset.iloc[[32556,32558]]

dataset.drop_duplicates()

dataset.duplicated(subset = "age").sum()

dataset.drop_duplicates(subset = "age", keep = "last", ignore_index = True)

"""## Valores faltantes"""

dataset.isna().sum() # NaN '?'

dataset.loc[dataset["workclass"].str.contains("\?")]

dataset["workclass"].str.contains("\?").sum()

colunas_categoricas = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']

for coluna in colunas_categoricas:
  #print(coluna)
  tem_interrogacao = dataset[coluna].str.contains("\?").any()
  if tem_interrogacao:
    print(f"Na coluna '{coluna}' existem valores '?'")

for coluna in colunas_categoricas:
  dataset[coluna] = dataset[coluna].replace(' ?', np.nan)

dataset.isna().sum()

dataset.fillna("NOT INFORMED").iloc[0:30]

dataset["workclass"].mode()

dataset["occupation"].mode()

dataset["native-country"].mode()

dataset["workclass"].fillna(dataset["workclass"].mode().iloc[0], inplace = True)

dataset["occupation"].fillna(dataset["occupation"].mode().iloc[0], inplace = True)

dataset["native-country"].fillna(dataset["native-country"].mode().iloc[0], inplace = True)

dataset.isna().sum()

dataset.dropna(subset = "workclass")

"""## Contagem"""

dataset.value_counts()

dataset.age.value_counts()

dataset.workclass.value_counts()

dataset.workclass.value_counts(normalize = True, sort = False)

for coluna in dataset.columns:
  if dataset[coluna].dtype == object:
    #print(coluna, dataset[coluna].dtype)
    print('-------', coluna, '-------')
    print(dataset[coluna].value_counts(normalize = True))
    print()

"""## Ordenação"""

dataset.sort_index(ascending = False)

dataset.sort_values(["age", "workclass", "education-num"], ascending = [False, True, False], inplace = True)

dataset

dataset.reset_index(drop = True, inplace = True)

dataset

"""## Filtragem"""

dataset.loc[dataset.education == ' Bachelors', ["age", "workclass", "education-num"]]

dataset.loc[(dataset["education-num"] == 6) & (dataset["marital-status"] == " Never-married")]

dataset.query("`education-num` == 6 and `marital-status` == ' Never-married'")

dataset.query("age > 35 and workclass == ' Private'")

dataset.query("age > 35 and workclass == ' Private'").loc[:,"capital-gain"].sum()

"""## Renomear e reordenar"""

dataset.columns = [coluna.upper() for coluna in dataset.columns]

dataset.columns

dataset.columns = [coluna.lower() for coluna in dataset.columns]

dataset.columns

dataset.rename(columns = {"age": "idade", "workclass": "trabalho"}, inplace = True)

dataset.columns

dataset.rename(columns = {"idade": "age", "trabalho": "workclass"}, inplace = True)

dataset.columns

dataset.head()

dataset = dataset.reindex(labels = ['workclass', 'age', 'education', 'education-num', 'marital-status',
       'occupation', 'relationship', 'race', 'sex', 'capital-gain',
       'capital-loos', 'hour-per-week', 'native-country', 'income'], axis = 1)

dataset

"""## Criação de colunas"""

dataset["hour-per-month"] = dataset["hour-per-week"] * 4

dataset.head()

dataset["high-education-level"] = dataset["education-num"] > 11

dataset.head()

dicionario_map = {" <=50K": "Low", " >50K": "High"}

dataset["category-income"] = dataset["income"].map(dicionario_map)

dataset

dataset["capital-gain-usd"] = dataset["capital-gain"].map(lambda x: f"USD {x}")

dataset.tail()

from datetime import datetime

datetime.now().year

dataset = dataset.assign(birth = datetime.now().year - dataset["age"],
                         hardwork = dataset["hour-per-week"] > 40)

dataset

dataset.loc[dataset["hardwork"] == True]

"""## Colunas categóricas"""

dataset.info()

dataset["native-country"].unique(), dataset["native-country"].nunique()

dataset = dataset.astype({"native-country": "category"})

dataset.info()

dataset

"""## Agregação"""

dataset.loc[:, "hour-per-week"].sum()

dataset.loc[:, ["hour-per-week", "age"]].sum()

dataset.loc[:, ["hour-per-week", "age"]].mean().round(2)

dataset.loc[:, ["hour-per-week", "age"]].std().round(2)

dataset.loc[:, ["hour-per-week", "age"]].min().round(2)

dataset.loc[:, ["hour-per-week", "age"]].max().round(2)

dataset.mean(numeric_only = True)

"""## Agrupamento"""

dataset["workclass"].unique()

dataset.groupby("workclass")["hour-per-week"].mean().sort_values(ascending = False)

group = dataset.groupby("workclass")["hour-per-week"].mean().sort_values(ascending = False)

type(group)

group

dataset.groupby("income")["education-num"].mean().round(2).sort_values(ascending = False)

group = dataset.groupby(["income", "workclass"])["hour-per-week"].mean().sort_index()
group

type(group)

group.index

group.loc[" <=50K"]

group.loc[(" <=50K", " Federal-gov"):(" <=50K", " Private")]

group.loc[" <=50K"][" Federal-gov":" Never-worked"]

group = dataset.groupby(["income", "workclass"], as_index = False)["hour-per-week"].mean().sort_index()
group

type(group)

group.query("workclass == ' Federal-gov'")

"""## Agrupamento com agregação"""

dataset.groupby(["income", "workclass"]).agg("mean", numeric_only = True)

dataset.groupby(["income", "workclass"]).agg({"age": ["mean", "std"],
                                              "hour-per-week": ["min", "max"]})

dataset.groupby(["income", "workclass"]).agg(age_mean = ("age", "mean"),
                                             age_std = ("age", "std"),
                                             hour_min = ("hour-per-week", "min"),
                                             hour_max = ("hour-per-week", "max"))

"""## Agregação com transform"""

group = dataset.groupby(["workclass"], as_index=False)["hour-per-week"].mean().sort_index()
group

group.assign(avg_age = dataset.groupby(["workclass"])["age"].transform("mean"),
             avg_education = dataset.groupby(["workclass"])["education-num"].transform("mean"))

"""## Tabelas pivot"""

dataset.pivot_table(index = "income",
                    columns = "workclass",
                    values = "age",
                    aggfunc = "mean",
                    margins = True)

dataset.pivot_table(index = "marital-status",
                    columns = "income",
                    values = "education-num",
                    aggfunc = "mean",
                    margins = True)

dataset.pivot_table(index = "marital-status",
                    columns = "income",
                    values = "education-num",
                    aggfunc = ("mean", "max", "min"))

dataset.pivot_table(index = "marital-status",
                    columns = "income",
                    values = "education-num",
                    aggfunc = ("mean", "max")).style.background_gradient(cmap = "Blues")

"""## Concatenação"""

data = {'idvenda': [123, 374, 654, 345],
        'data': ['2024-01-19', '2024-01-20', '2024-02-21', '2024-02-25'],
        'idvendedor': [1, np.nan, 2, 3],
        'valor_total': [45.76, 102.34, 56.34, 34.21]}
df1 = pd.DataFrame.from_dict(data)
df1

data = {'idvenda': [546, 232, 789, 2345],
        'data': ['2024-01-22', '2024-01-22', '2024-01-23', '2024-01-24'],
        'idvendedor': [3, 2, 1, 2],
        'valor_total': [45.76, 102.34, 56.34, 34.21]}
df2 = pd.DataFrame.from_dict(data)
df2

data_complete = pd.concat([df1, df2], ignore_index = True)
data_complete

data_complete.query("idvendedor == 1")

"""## Junção"""

data = {'idvendedor': [1, 2, 3, 4],
        'nome': ['Julia', 'Paulo', 'Jéssica', 'Marcos']}
df_vendedor = pd.DataFrame.from_dict(data)
df_vendedor

data_complete.merge(df_vendedor,
                    how = "inner",
                    left_on = ["idvendedor"],
                    right_on = ["idvendedor"])

data_complete = data_complete.merge(df_vendedor,
                    how = "left",
                    left_on = ["idvendedor"],
                    right_on = ["idvendedor"])

data_complete

data_complete.query("nome == 'Jéssica'")

"""## Conversão e formatações para data"""

df_vendas = data_complete.copy()

df_vendas.info()

df_vendas.loc[0, ["data"]] = "N/A"

df_vendas

df_vendas = df_vendas.astype({"data": "datetime64"})

# https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html
df_vendas = df_vendas.assign(data = pd.to_datetime(df_vendas["data"],
                                                   infer_datetime_format=True,
                                                   errors = "coerce")) # NaT -> NaN

df_vendas

df_vendas.info()

"""### Formatação

- https://www.programiz.com/python-programming/datetime/strftime
"""

df_vendas.assign(data2 = df_vendas["data"].dt.strftime("%Y-%b-%a"),
                 data3 = df_vendas["data"].dt.strftime("%d-%m-%Y"))

df_vendas["data"].fillna("2024-01-19", inplace = True)

df_vendas

df_vendas["data"].dt.year

df_vendas["data"].dt.month

df_vendas["data"].dt.day

df_vendas["data"].dt.hour

df_vendas["data"].dt.minute

df_vendas["data"].dt.second

df_vendas["data"].dt.quarter

"""## Índices com data"""

df_vendas2 = df_vendas.copy()
df_vendas2

df_vendas2.dtypes

df_vendas2.set_index("data", inplace = True)
df_vendas2

df_vendas2.loc["2024"]

df_vendas2.loc["2024-01":"2024-02"]

df_vendas2.loc["2024-01-22":"2024-01"]

df_vendas2

df_vendas2.resample('M')["valor_total"].sum(numeric_only = True)

df_vendas2.resample('D')["valor_total"].sum(numeric_only = True)

df_vendas2.resample('D')["valor_total"].mean(numeric_only = True)

"""## Importação e exportação

- Documentação: https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html
"""

dataset = pd.read_csv('census.csv').head(5)
dataset

dataset = pd.read_csv('census.csv', header = None).head(5)
dataset

colunas = ['age',	'workclass', 'final-weight', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loos', 'hour-per-week', 'native-country', 'income']
dataset = pd.read_csv('census.csv', header = None, names = colunas).head(5)
dataset

dataset = pd.read_csv('census.csv', usecols = ["age", "workclass"]).head(5)
dataset

dataset = pd.read_csv('census.csv', na_values = [" ?"])

dataset.isna().sum()

dataset.dtypes

dataset = pd.read_csv('census.csv', dtype = ({"final-weight": "float"}))
dataset.dtypes

dataset = pd.read_csv('AirPassengers.csv', parse_dates = ["Month"],
                      infer_datetime_format = True, index_col = "Month")
dataset

moeda = lambda x: f"{x} USD"
dataset = pd.read_csv('census.csv', converters = {"capital-gain": moeda})
dataset

# https://archive.ics.uci.edu/ml/machine-learning-databases/00236/seeds_dataset.txt
dataset = pd.read_csv('seeds_dataset.txt', sep = "\t",
                      header = None, names = ["a", "b", "c", "d", "e", "f", "g", "h"])
dataset

dataset = pd.read_excel('seeds.xlsx', sheet_name = "Planilha2")
dataset

dataset.to_csv('teste.csv', index = False)

dataset.to_excel('teste.xlsx', sheet_name = "testando", index = False)

"""# Gráficos

## Gráfico básico de linhas

- Documentação: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html
"""

dataset = pd.read_csv('AirPassengers.csv')
dataset

dataset.plot();

dataset.set_index("Month").plot();

dataset.plot(x = "Month");

dataset.set_index("Month").loc["1949-01":"1949-12"].plot();

"""## Formatação"""

dataset.set_index("Month").loc["1949-01":"1949-12"].plot(title = "Voos em 1949",
                                                         xlabel = "Data",
                                                         ylabel = "Quantidade",
                                                         color = "red",
                                                         style = "-.",
                                                         legend = True).legend(bbox_to_anchor = (1.3,1));

# Estilos: https://seaborn.pydata.org/generated/seaborn.set_style.html
import seaborn as sns
sns.set_style("darkgrid")

dataset.set_index("Month").loc["1949-01":"1949-12"].plot(title = "Voos em 1949",
                                                         xlabel = "Data",
                                                         ylabel = "Quantidade",
                                                         color = "red",
                                                         style = "-.",
                                                         legend = True).legend(bbox_to_anchor = (1.3,1));

"""## Sub-gráficos"""

dataset = pd.read_csv('census.csv')
dataset.dtypes

dataset.plot(subplots = True);

dataset.plot(subplots = True, layout = (3, 3), figsize = (10,10),
             title = ["Age", "Final", "Education", "Gain", "Loss", "Hous"],
             legend = False, kind = "hist");

"""## Gráfico de barras"""

dataset.workclass.unique()

dataset.groupby("workclass")["age"].count().plot(kind = "bar");

dataset.groupby("workclass")["age"].count().plot.barh();

pivot = dataset.query("workclass != ' Never-worked' and workclass != ' Without-pay'").pivot_table(index = "income",
                            columns = "workclass",
                            values = "education-num",
                            aggfunc = "sum").apply(lambda x: x * 100 / sum(x), axis = 1)
pivot

pivot.plot.bar().legend(bbox_to_anchor = (1.4,1));

pivot.plot.bar(stacked = True).legend(bbox_to_anchor = (1.4,1));

"""## Gráfico de pizza"""

dataset.groupby("workclass")["age"].count().plot.pie(title = "Workclass", ylabel = "");

"""## Gráfico de dispersão"""

dataset.columns

dataset.plot.scatter(x = "education-num", y = "capital-gain");

dataset.plot.scatter(x = "education-num", y = "income");

dataset.plot.scatter(x = "hour-per-week", y = "education-num");

dataset.plot.scatter(x = "hour-per-week", y = "capital-gain");

"""## Histograma"""

dataset["age"].plot.hist();

dataset["education-num"].plot.hist();

dataset["capital-gain"].plot.hist();

dataset[["age", "education-num"]].plot.hist(alpha = 0.4);

plot = dataset.plot.hist(alpha = 0.3);

plot.figure.savefig("histograma.png")